---
title: 10-11-TD
date: 2021-10-11 20:12:16
tags:
- 일상
categories:
- 일상
- TIL
---
# 10/11일
주말동안 stargan + Wasserstein GAN(WGAN) 논문을 정독해서 읽기 시작하였다.  
multi domain image to image Translation 을 실현시킨 Stargan과 GAN의 loss함수를 Earth Move distance(EMD)로 설정을 하여 Discriminator 와 Generator 간의 불균형 문제를 해결한 WGAN에 대하여 간략하게 정리하려고 한다.(요약이 아닌 리뷰포스트는 현재 WGAN을 보면서 작성중이다.)

## StarGAN논문 요약
1. 여러 domain 간 변환을 1개의 Generator를 이용하여 변환할 수 있는것을 목표로 하는 논문이다.
2. Discriminator는 Real/Fake를 판단하는 것 뿐만아니라 domain Classfication(이 이미지가 어떤 domain에 속해있는지)까지 학습 해야한다.
3. 두개의 Generator를 사용하여 Cycle을 형성하여 학습하는 CycleGAN과 달리 하나의 Generator로 Fake image를 생성, Fake image와 기존 Source Image의 도메인 정보를 이용하여 다시 재구성을 하여 사이클 구조를 이룬다.
4. 그래서 3개의 Loss function을 조합하여 Generator와 Discriminator를 학습시킨다.
   * $\mathcal{L}_{abv}$ 는 Adversarial Loss(minmax Loss) : 기본적인 GAN Loss, Cross Entropy에서 가져와 변형시켜서 만들었다. 실제로 학습시킬때는 WGAN의 EMD를 변형시켜서 Loss function 으로 사용했다.
   * Domain Classification Loss : Classfication loss(Cross Entropy Loss)  
   * Reconstruction Loss : CycleGAN의 Cycle consistency loss를 사용(생성된 이미지를 다시 원래 source 이미지로 되돌렸을때 발생하는 차이에 대한 척도)

stargan  
https://arxiv.org/abs/1711.09020

WGAN은 좀 더 시간이 필요할듯 하다.
막상 요약해서 쓰려고 하니까 수학적 베이스가 많이 필요한데 아직 내가 정리할 정도로 이해를 한것 같지 않다.

+오늘 공부 하면서 조금 더 조사해봐야겠다 생각되었던 부분
* OS 어떤구조를 가지고 있는지 (Linux, Windows에 관하여 이왕이면 차이도 조사하면 좋을것 같다) : 내부의 프로세스, 스케줄링, 페이징 교체 작업 같은 세부적인건 어느정도 설명이 가능한데 os가 전체적으로 어떤 구조인지 이야기 하라고 하면 못 할것 같다.
* 커널에 대해 지식이 부족함을 느꼈다. 대략적으로는 아는데 자세하게는 못말하는 느낌이다. 한번 자세히 조사할 필요가 있다고 생각한다.
* 각종 Loss 함수에 대한 공부(이 함수가 어디에서 비롯되었는지 궁금해졌다.)
* Duality 등의 WGAN에 대한 수학적 베이스에 대한 공부(Lipschitz조건, Kantorovich-Rubinstein duality)